

# **Advanced Express.js User API (TypeScript)**

### High-Performance Caching â€¢ Intelligent Rate Limiting â€¢ Async Processing â€¢ Frontend Tester

This project is a **high-performance backend system** built with **Express.js + TypeScript**, designed to handle heavy traffic efficiently through:

* **LRU caching**
* **Concurrent request coalescing**
* **Background stale cleanup**
* **Custom rate limiting (with burst handling)**
* **Asynchronous queue for non-blocking DB simulation**
* **Simple HTML frontend to test all endpoints**

This architecture models **real-world scalable systems**, similar to what companies like Netflix, Meta, and Amazon use in microservices.



# ğŸŒŸ **Why This System Matters (Benefits)**

This backend demonstrates **exactly the kind of optimizations used in high-traffic production environments.**
Hereâ€™s how each part benefits performance and reliability:



## ğŸ§  **1. LRU Cache (with TTL) â€” Massive Performance Boost**

**Benefit:** Faster responses, reduced server load, reduced database load.

* Stores frequently accessed user data.
* Returns cached responses instantly (0â€“2 ms).
* Automatically expires entries after **60 seconds**.
* Removes least recently used entries when full (LRU eviction).

ğŸ‘‰ **Real-world impact:**
Twitter, Instagram, and YouTube use LRU caches to handle billions of reads per day while reducing database pressure by 90%.

---

## ğŸš¥ **2. Advanced Rate Limiting â€” Protects the Server**

**Benefit:** Prevents spam, abuse, DDoS-like traffic, or accidental overload.

This system uses **dual token buckets**:

* **10 requests per minute**
* **Burst capacity: 5 requests per 10 seconds**

ğŸ‘‰ **Real-world impact:**
Rate limiting is critical for protecting APIs against abuse, especially public-facing ones.

---

## ğŸ”„ **3. Concurrent Request Coalescing â€” Elegant Load Reduction**

**Benefit:** Prevents duplicated work under heavy load.

If multiple users request the same user ID at the same time:

* Only **one** simulated DB call runs
* All others **wait for the same promise**
* They return `"source": "coalesced"`

ğŸ‘‰ **Real-world impact:**
This is how CDNs (Cloudflare, Akamai) avoid â€œthundering herdâ€ problems.

---

## ğŸ§µ **4. Asynchronous Processing with Queue â€” No Blocking**

**Benefit:** Handles high concurrency without slowing down.

The async queue simulates database operations (200ms delay) using controlled concurrency (5 at a time).

ğŸ‘‰ **Real-world impact:**
This models job queues used in microservices (BullMQ, RabbitMQ, SQS).

---

## ğŸ§¹ **5. Stale Entry Cleanup (Background Worker)**

**Benefit:** Prevents memory leaks by removing expired cache entries every 10 seconds.

ğŸ‘‰ **Real-world impact:**
Long-running servers in production MUST clean stale memory to avoid crashes.

---

## ğŸ–¥ **6. Simple HTML Frontend â€” Makes Testing Easy**

**Benefit:** Users can test all API endpoints visually, no Postman needed.

Buttons provided for:

* GET /users/:id
* POST /users
* DELETE /cache
* GET /cache-status
* GET /health

Shows full JSON response in a clean UI.

ğŸ‘‰ Perfect for testing & demonstrating system behavior.

---

# ğŸ— **Project Architecture**

```
express-user-api/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts           # Main API + routes + logic
â”‚   â”œâ”€â”€ mockData.ts        # Mock users database
â”‚   â”œâ”€â”€ lruCache.ts        # LRU cache (TTL + eviction)
â”‚   â”œâ”€â”€ asyncQueue.ts      # Async DB queue
â”‚   â”œâ”€â”€ rateLimiter.ts     # Burst-aware rate limiter
â”‚
â”œâ”€â”€ index.html             # Simple frontend tester
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

# ğŸ”§ **Installation**

### 1. Install dependencies

```bash
npm install
```

### 2. Run in development mode

```bash
npm run dev
```

### 3. Run in production mode

```bash
npm run build
npm start
```

Server runs on:

```
http://localhost:3000
```

---

# ğŸ§ª **Testing the API**

You can use **Postman**, **Thunder Client**, or the included **index.html** file.

Open the HTML tester:

```
index.html
```

It supports:

| Endpoint          | What It Does                                |
| ----------------- | ------------------------------------------- |
| GET /users/:id    | Cache + coalescing + async queue            |
| POST /users       | Creates a new user                          |
| DELETE /cache     | Clears entire cache                         |
| GET /cache-status | Shows hits, misses, size, avg response time |
| GET /health       | Server status                               |

All response bodies are shown in a live JSON box.

---

# âš¡ **Endpoints Overview**

### **GET /users/:id**

* Returns user from:

  * Cache
  * or coalesced request
  * or simulated DB
* First call: ~200ms
* Next calls: ~0ms (cache hit)

---

### **POST /users**

Creates a new user and caches it immediately.

---

### **DELETE /cache**

Clears all cached entries + resets stats.

---

### **GET /cache-status**

Shows:

```json
{
  "size": 3,
  "hits": 4,
  "misses": 2,
  "avgResponseTimeMs": 145.25
}
```

---

### **GET /health**

Simple health check.

---

# ğŸ¯ **Why This Project is Valuable to Learn / Submit**

This backend demonstrates **professional-level engineering concepts** such as:

* caching strategies
* eviction policies
* concurrency control
* asynchronous task management
* rate limiting
* performance monitoring
* real-world API design patterns

It shows you understand:

* scalability
* optimization
* backend architecture
* data flow
* memory management
* latency reduction

This is exactly the kind of system used in:

* high-traffic websites
* microservice platforms
* enterprise-level backend engineering
